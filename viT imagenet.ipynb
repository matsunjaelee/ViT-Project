{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf44606-b528-4760-a3e5-6d327429c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision==0.10.0\n",
      "  Downloading torchvision-0.10.0-cp39-cp39-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/mattlee/.local/lib/python3.9/site-packages (from torch==1.9.0) (4.12.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0) (1.22.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0) (9.0.0)\n",
      "Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m636.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:03\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.10.0-cp39-cp39-manylinux1_x86_64.whl (22.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/mattlee/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/mattlee/.local/lib/python3.9/site-packages/~-rch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0\n",
      "    Uninstalling torchvision-0.19.0:\n",
      "      Successfully uninstalled torchvision-0.19.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/mattlee/.local/lib/python3.9/site-packages/~orchvision.libs'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/mattlee/.local/lib/python3.9/site-packages/~orchvision'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed torch-1.9.0 torchvision-0.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install torch==1.9.0 torchvision==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4fa957-57be-4e08-82fc-d3d3ace4e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/net/a1x256-ai01/hotel/mattlee/myproject/myenv/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18f94b-7df3-432d-96d2-b43b45ff8994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c760502-4613-4e90-8ba9-c5c6a40b8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pytorch_pretrained_vit import ViT\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a4767e-9276-4d74-9ca7-73edd4217d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('image_classifications.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS predictions (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        class_name TEXT,\n",
    "        image_path TEXT,\n",
    "        top1 TEXT, top1_conf REAL,\n",
    "        top2 TEXT, top2_conf REAL,\n",
    "        top3 TEXT, top3_conf REAL,\n",
    "        top4 TEXT, top4_conf REAL,\n",
    "        top5 TEXT, top5_conf REAL\n",
    "    )\n",
    "''')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1080b6b1-e7a6-4293-904b-9ae00754f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used.\n",
      "GPU model: Quadro RTX 8000\n",
      "Tensor: tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used.\")\n",
    "    print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead.\")\n",
    " \n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x = x.to(device)\n",
    "print(f\"Tensor: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cca25-27ea-4010-b8cb-d03397b4df09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e8e9cf-3121-47c0-a994-22f3fca8a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n",
      "tench,n01440764\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     top5_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[top5_indices]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     53\u001b[0m     top5_labels \u001b[38;5;241m=\u001b[39m [index_tosynset_label[\u001b[38;5;28mstr\u001b[39m(idx)][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m top5_indices]\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43mINSERT INTO predictions (class_name, image_path, top1, top1_conf,\u001b[39;49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;43m                                            top2, top2_conf, top3, top3_conf,\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;43m                                            top4, top4_conf, top5, top5_conf)\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;43m                             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop5_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop5_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtop5_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop5_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtop5_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop5_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtop5_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop5_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtop5_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop5_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m     68\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m/\u001b[39m total \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'B_16_imagenet1k'\n",
    "model = ViT(model_name, pretrained=True)\n",
    "model.eval()\n",
    "    \n",
    "index_tosynset_label = json.load(open('ImageNet_class_index.json'))\n",
    "index_to_classname = json.load(open('imagenet-simple-labels.json'))\n",
    "\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "    transforms.Resize(model.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "data_dir = 'final_val/'\n",
    "correct, total = 0,0\n",
    "\n",
    "for synset_folder in sorted(os.listdir(data_dir)):\n",
    "    \n",
    "    synset_path = os.path.join(data_dir, synset_folder)\n",
    "    if not os.path.isdir(synset_path):\n",
    "        continue\n",
    "    class_name = index_to_classname[total]\n",
    "   \n",
    "    print(class_name + \",\" + synset_folder)\n",
    "    img_name = next((f for f in os.listdir(synset_path) if os.path.isfile(os.path.join(synset_path, f))), None)\n",
    "    \n",
    "    if img_name is None:\n",
    "        continue\n",
    "    img_path = os.path.join(synset_path, img_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = tfms(img).unsqueeze(0) \n",
    " \n",
    "    with torch.no_grad():\n",
    "        outputs = model(img).squeeze(0)\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "    predicted_idx = torch.argmax(outputs).item()\n",
    "    predicted_idx_str = str(predicted_idx)\n",
    "        # Map to synset and human-readable label\n",
    "    predicted_synset, predicted_label = index_tosynset_label[predicted_idx_str]\n",
    "\n",
    "        # Compare the predicted synset with the folder's synset\n",
    "    if predicted_synset == synset_folder:\n",
    "        correct += 1\n",
    "        \n",
    "    total += 1\n",
    "    \n",
    "    top5_indices = torch.topk(outputs, k=5).indices.tolist()\n",
    "    top5_probs = torch.softmax(outputs, dim=0)[top5_indices].tolist()\n",
    "\n",
    "    top5_labels = [index_tosynset_label[str(idx)][1] for idx in top5_indices]\n",
    "    \n",
    "    cursor.execute('''INSERT INTO predictions (class_name, image_path, top1, top1_conf,\n",
    "                                            top2, top2_conf, top3, top3_conf,\n",
    "                                            top4, top4_conf, top5, top5_conf)\n",
    "                             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                        (class_name, img_path, top5_labels[0], top5_probs[0],\n",
    "                        top5_labels[1], top5_probs[1],\n",
    "                        top5_labels[2], top5_probs[2],\n",
    "                        top5_labels[3], top5_probs[3],\n",
    "                        top5_labels[4], top5_probs[4]))\n",
    "    conn.commit()\n",
    "\n",
    "        \n",
    "        \n",
    "accuracy = correct / total * 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "conn.close()\n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a7945-8e16-4ae5-9210-9563f77cd155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1765cee1-4d2e-4516-a879-983d06d647df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Record from Database:\n",
      "ID: 1\n",
      "Class Name: tench\n",
      "Image Path: final_val/n01440764/ILSVRC2012_val_00031094.JPEG\n",
      "Top 1 Prediction: tench with confidence 0.99\n",
      "Top 2 Prediction: barracouta with confidence 0.01\n",
      "Top 3 Prediction: reel with confidence 0.00\n",
      "Top 4 Prediction: pole with confidence 0.00\n",
      "Top 5 Prediction: coho with confidence 0.00\n",
      "Sample Record from Database:\n",
      "ID: 2\n",
      "Class Name: goldfish\n",
      "Image Path: final_val/n01443537/ILSVRC2012_val_00028713.JPEG\n",
      "Top 1 Prediction: goldfish with confidence 1.00\n",
      "Top 2 Prediction: coral_reef with confidence 0.00\n",
      "Top 3 Prediction: rock_beauty with confidence 0.00\n",
      "Top 4 Prediction: tench with confidence 0.00\n",
      "Top 5 Prediction: lionfish with confidence 0.00\n",
      "Sample Record from Database:\n",
      "ID: 3\n",
      "Class Name: great white shark\n",
      "Image Path: final_val/n01484850/ILSVRC2012_val_00017194.JPEG\n",
      "Top 1 Prediction: great_white_shark with confidence 0.97\n",
      "Top 2 Prediction: tiger_shark with confidence 0.02\n",
      "Top 3 Prediction: hammerhead with confidence 0.00\n",
      "Top 4 Prediction: electric_ray with confidence 0.00\n",
      "Top 5 Prediction: dugong with confidence 0.00\n"
     ]
    }
   ],
   "source": [
    "def fetch_sample(offset):\n",
    "    # connect to the sqlite3 database\n",
    "    conn = sqlite3.connect('image_classifications.db')\n",
    "    c = conn.cursor()\n",
    " \n",
    "    c.execute(f'SELECT * FROM predictions LIMIT 1 OFFSET {offset}')\n",
    "    record = c.fetchone()\n",
    " \n",
    "    # check if a record was found\n",
    "    if record:\n",
    "        print(\"Sample Record from Database:\")\n",
    "        print(f\"ID: {record[0]}\")\n",
    "        print(f\"Class Name: {record[1]}\")\n",
    "        print(f\"Image Path: {record[2]}\")\n",
    "        print(f\"Top 1 Prediction: {record[3]} with confidence {record[4]:.2f}\")\n",
    "        print(f\"Top 2 Prediction: {record[5]} with confidence {record[6]:.2f}\")\n",
    "        print(f\"Top 3 Prediction: {record[7]} with confidence {record[8]:.2f}\")\n",
    "        print(f\"Top 4 Prediction: {record[9]} with confidence {record[10]:.2f}\")\n",
    "        print(f\"Top 5 Prediction: {record[11]} with confidence {record[12]:.2f}\")\n",
    "    else:\n",
    "        print(\"No more records found.\")\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "fetch_sample(0)\n",
    "fetch_sample(1)\n",
    "fetch_sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d701c-b3f0-431e-a4d2-01daeabe2217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadd4a6-9bf8-4b72-bb32-f89cd9c4ace7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242e5be-649f-446e-aa50-0f2406847ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
